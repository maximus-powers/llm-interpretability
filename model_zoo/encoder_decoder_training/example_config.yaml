# Encoder-Decoder Training Configuration
# For training weight-space autoencoders on neural network weights

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================
dataset:
  hf_dataset: "maximuspowers/muat-mean-std-fourier-5-pca-10-medium"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  input_mode: "weights"    # weights, signature, both

  max_dimensions: # Only needed if input_mode "signature"
    max_hidden_layers: 9
    max_neurons_per_layer: 40
    max_sequence_length: 7
  
  neuron_profile: # Only needed if input_mode "signature"
    # list of methods to use from signatures, make sure your signature contains the ones you choose.
    # they will be concatenated in the order given before being used as input
    methods: ["mean", "std"]  # mean, std, max, min, sparsity, entropy, pca, svd, clustering, fourier, pattern_wise

# ============================================================================
# TOKENIZATION CONFIGURATION
# ============================================================================
tokenization:
  granularity: "neuron"              # "neuron" for per-neuron tokenization, "chunk" for legacy chunking
  chunk_size: 64                     # Only used when granularity="chunk": weight values per token
  max_tokens: 512                    # Maximum sequence length
  include_metadata: true             # true, false (metadata is layer_idx, param_type, position, shape_encoding, token_idx)

# ============================================================================
# MODEL ARCHITECTURE
# ============================================================================
architecture:
  type: "transformer"                # mlp, transformer
  latent_dim: 256                    # Latent dimension (bottleneck size)

  # ===== MLP Architecture (used if type="mlp") =====
  mlp:
    token_pooling: "mean"            # mean, max, flatten
    encoder:
      hidden_dims: [512, 384, 256]   # Hidden layer dimensions                    # List of integers, each = one layer
      dropout: 0.2                   # Dropout probability                        # 0.0-1.0
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      batch_norm: true               # true, false
    decoder:
      hidden_dims: [256, 384, 512]   # Hidden layer dimensions                    # List of integers, each = one layer
      dropout: 0.2                   # Dropout probability                        # 0.0-1.0
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      batch_norm: true               # true, false

  # ===== Transformer Architecture (used if type="transformer") =====
  transformer:
    encoder:
      d_model: 512                   # Model dimension
      num_heads: 8                   # d_model must be divisible by this
      num_layers: 6                  # Number of transformer layers
      dim_feedforward: 2048          # Feed-forward dimension, typically 4x d_model
      dropout: 0.1                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      positional_encoding: "learned" # learned, sinusoidal
      pooling: "mean"                # mean, max, cls_token
    decoder:
      d_model: 512                   # Model dimension, should match encoder d_model
      num_heads: 8                   # d_model must be divisible by this
      num_layers: 6                  # Number of transformer layers
      dim_feedforward: 2048          # Feed-forward dimension, typically 4x d_model
      dropout: 0.1                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid

# ============================================================================
# LOSS CONFIGURATION
# ============================================================================
loss:
  type: "mse"                        # mse, mae, cosine, combined, contrastive

  # ===== Combined Loss (multiple reconstruction losses) =====
  # components:
  #   - type: "mse"                  # Component loss type
  #     weight: 1.0                  # Component weight
  #   - type: "cosine"
  #     weight: 0.5

  # ===== Contrastive Loss (Supervised) =====
  # Uses behavior labels from dataset metadata (selected_patterns) to define positive pairs.
  # Networks sharing ANY behavior pattern are treated as positive pairs.
  #
  # gamma: 0.5                       # Balance contrastive/reconstruction, 0.0-1.0 (0=recon only, 1=contrast only)
  # temperature: 0.1                 # Temperature for contrastive loss, typically 0.1-0.5 (smaller=harder clustering)
  # reconstruction_type: "mse"       # mse, mae, cosine
  #
  # # Optional projection head for contrastive learning (2-layer MLP)
  # projection_head:
  #   input_dim: 256                 # Should match architecture.latent_dim
  #   hidden_dim: 256                # Hidden layer size, typically same as input_dim
  #   output_dim: 128                # Projection output dimension

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  optimizer: "adam"                  # adam (only option currently)
  learning_rate: 0.0001              # Learning rate
  weight_decay: 0.0001               # Weight decay (L2 regularization)
  epochs: 200                        # Number of training epochs
  batch_size: 16                     # Training batch size

  early_stopping:
    enabled: true
    patience: 5
    monitor: "val_loss"              # val_loss, val_mse, val_r2_score, etc.
    mode: "min"                      # Optimization direction, min (lower is better), max (higher is better)

  lr_scheduler:
    enabled: true                    # Enable LR scheduling
    type: "reduce_on_plateau"        # Scheduler type
    patience: 3                     # Epochs without improvement before reducing
    factor: 0.5                      # LR reduction factor
    min_lr: 0.000001

# ============================================================================
# EVALUATION CONFIGURATION
# ============================================================================
evaluation:
  metrics:                           # mse, mae, rmse, cosine_similarity, relative_error, r2_score
    - "mse"
    - "mae"
    - "rmse"
    - "cosine_similarity"
    - "relative_error"
    - "r2_score"

  per_layer_metrics: false           # Compute per-layer breakdown

# ============================================================================
# LOGGING & CHECKPOINTING
# ============================================================================
logging:
  tensorboard:
    enabled: true
    log_interval: 10                 # Log every N batches
    auto_launch: true
    port: 6006                       # server port
  checkpoint:
    enabled: true
    save_best_only: true
    monitor: "val_loss"              # Metric to monitor for "best", val_loss, val_mse, val_r2_score, etc.
    mode: "min"                      # Optimization direction, min (lower is better), max (higher is better)
  verbose: true

# ============================================================================
# HUGGINGFACE HUB INTEGRATION
# ============================================================================
hub:
  enabled: true
  repo_id: "maximuspowers/weight-autoencoder-mlp-v1"
  token: null                        # String or null (uses HF_TOKEN env var)
  private: false
  push_model: true
  push_logs: true
  push_metrics: true
  # Both encoder.pt and decoder.pt will be uploaded to the same repository

# ============================================================================
# DEVICE & DATA LOADING
# ============================================================================
device:
  type: "auto" # "auto", "cuda", "mps", or "cpu"

dataloader:
  num_workers: 0
  pin_memory: true

# ============================================================================
# RUN DIRECTORY MANAGEMENT
# ============================================================================
# delete run directory after training
run_log_cleanup: false
