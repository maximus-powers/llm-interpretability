# Encoder-Decoder Training Configuration
# For training weight-space autoencoders on neural network weights

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================
dataset:
  hf_dataset: "maximuspowers/muat-mean-std-fourier-5-pca-10-medium"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  input_mode: "weights"    # weights, signature, both

  max_dimensions: # Only needed if input_mode "signature" or "both"
    max_hidden_layers: 9
    max_neurons_per_layer: 40
    max_sequence_length: 7

  neuron_profile: # Only needed if input_mode "signature" or "both"
    # list of methods to use from signatures, make sure your signature contains the ones you choose.
    # they will be concatenated in the order given before being used as input
    methods: ["mean", "std"]  # mean, std, max, min, sparsity, entropy, pca, svd, clustering, fourier, pattern_wise

# ============================================================================
# TOKENIZATION CONFIGURATION
# ============================================================================
tokenization:
  granularity: "neuron"              # "neuron" for per-neuron tokenization, "chunk" for legacy chunking
  chunk_size: 64                     # Only used when granularity="chunk": weight values per token
  max_tokens: 512                    # Maximum sequence length

# ============================================================================
# MODEL ARCHITECTURE
# ============================================================================
architecture:
  type: "transformer"                # mlp, transformer
  latent_dim: 256                    # Latent dimension (bottleneck size)

  # Architecture encoder for FiLM conditioning (bypasses latent space)
  arch_encoder:
    embed_dim: 64                    # Architecture embedding dimension

  # ===== MLP Architecture (used if type="mlp") =====
  mlp:
    token_pooling: "mean"            # mean, max, flatten
    encoder:
      hidden_dims: [512, 384, 256]   # Hidden layer dimensions
      dropout: 0.2                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      batch_norm: true               # true, false
    decoder:
      hidden_dims: [256, 384, 512]   # Hidden layer dimensions
      dropout: 0.2                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      batch_norm: true               # true, false

  # ===== Transformer Architecture (used if type="transformer") =====
  transformer:
    encoder:
      d_model: 512                   # Model dimension
      num_heads: 8                   # d_model must be divisible by this
      num_layers: 6                  # Number of transformer layers
      dim_feedforward: 2048          # Feed-forward dimension, typically 4x d_model
      dropout: 0.1                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      positional_encoding: "learned" # Type: learned, sinusoidal (only used if use_positional_encoding=true)
      use_positional_encoding: false # Disable encoder positional encoding (architecture bypasses latent)
      pooling: "mean"                # mean, max, cls_token
    decoder:
      d_model: 512                   # Model dimension, should match encoder d_model
      num_heads: 8                   # d_model must be divisible by this
      num_layers: 6                  # Number of transformer layers
      dim_feedforward: 2048          # Feed-forward dimension, typically 4x d_model
      dropout: 0.1                   # Dropout probability (0.0-1.0)
      activation: "relu"             # relu, gelu, tanh, leaky_relu, sigmoid
      num_memory_tokens: 8           # Number of memory tokens to expand latent into (prevents collapse)

# ============================================================================
# LOSS CONFIGURATION
# Enable/disable each loss type and set its weight independently
# Weights are normalized to sum to 1.0 (e.g., 1.0:0.3:0.5 -> 55%:17%:28%)
# ============================================================================
loss:
  # Reconstruction loss - token-level comparison between original and reconstructed
  reconstruction:
    enabled: true
    type: "mse"                      # mse, mae, cosine, combined
    weight: 1.0

  # Contrastive loss - pulls same-behavior models together in latent space
  # Uses behavior labels from dataset metadata (selected_patterns) to define positive pairs.
  # Networks sharing ANY behavior pattern are treated as positive pairs.
  contrastive:
    enabled: false
    weight: 0.3                      # Weight relative to other losses
    temperature: 0.1                 # Temperature for softmax (smaller = harder clustering)
    # Optional projection head for contrastive learning (2-layer MLP)
    projection_head:
      input_dim: 256                 # Should match architecture.latent_dim
      hidden_dim: 128                # Hidden layer size
      output_dim: 64                 # Projection output dimension

  # Functional loss - evaluates whether reconstructed weights produce correct model outputs
  # This loss detokenizes weights, loads them into models, and compares outputs on test inputs.
  # Ensures decoder learns to produce functionally correct weights, not just token-similar ones.
  functional:
    enabled: false
    weight: 0.5                      # Weight relative to other losses
    test_samples: null               # null = use all, 0.0-1.0 = percentage of benchmark
    benchmark_path: "model_zoo/configs/rep_eng/benchmark_dataset.json"

  # Variance regularization loss - prevents decoder collapse to uniform outputs
  # Penalizes when output variance across token positions falls below target.
  # Essential for preventing the decoder from outputting the same values everywhere.
  variance:
    enabled: true                    # Strongly recommended to prevent collapse
    weight: 0.1                      # Weight relative to other losses
    target_variance: 0.01            # Minimum desired variance across positions

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  optimizer: "adamw"                 # AdamW with decoupled weight decay
  learning_rate: 0.0001              # Learning rate
  weight_decay: 0.0001               # Weight decay (L2 regularization)
  max_grad_norm: 1.0                 # Maximum gradient norm for clipping
  epochs: 200                        # Number of training epochs
  batch_size: 16                     # Training batch size
  gradient_accumulation_steps: 1     # Effective batch size = batch_size * this

  early_stopping:
    enabled: true
    patience: 10
    monitor: "val_loss"              # val_loss, val_mse, val_r2_score, etc.
    mode: "min"                      # min (lower is better), max (higher is better)

  lr_scheduler:
    enabled: true                    # Enable LR scheduling (ReduceLROnPlateau)
    patience: 5                      # Epochs without improvement before reducing
    factor: 0.5                      # LR reduction factor
    min_lr: 0.000001

# ============================================================================
# EVALUATION CONFIGURATION
# ============================================================================
evaluation:
  metrics:                           # mse, mae, rmse, cosine_similarity, relative_error, r2_score
    - "mse"
    - "mae"
    - "rmse"
    - "cosine_similarity"
    - "relative_error"
    - "r2_score"

  per_layer_metrics: false           # Compute per-layer breakdown

# ============================================================================
# LOGGING & CHECKPOINTING
# ============================================================================
logging:
  tensorboard:
    enabled: true
    log_interval: 10                 # Log scalars every N batches
    auto_launch: true
    port: 6006                       # server port
    # Advanced visualizations (histograms, embeddings, weight heatmaps)
    visualizations:
      enabled: true
      log_interval: 5                # Log visualizations every N epochs
      num_image_samples: 4           # Number of weight heatmap samples
  checkpoint:
    enabled: true
    save_best_only: true
    monitor: "val_loss"              # Metric to monitor for "best"
    mode: "min"                      # min (lower is better), max (higher is better)
  verbose: true

# ============================================================================
# HUGGINGFACE HUB INTEGRATION
# ============================================================================
hub:
  enabled: true
  repo_id: "maximuspowers/weight-autoencoder-mlp-v1"
  token: null                        # String or null (uses HF_TOKEN env var)
  private: false
  push_model: true
  push_logs: true
  push_metrics: true

# ============================================================================
# DEVICE & DATA LOADING
# ============================================================================
device:
  type: "auto"                       # "auto", "cuda", "mps", or "cpu"

dataloader:
  num_workers: 0
  pin_memory: true

# ============================================================================
# RUN DIRECTORY MANAGEMENT
# ============================================================================
run_log_cleanup: false               # Delete run directory after training
