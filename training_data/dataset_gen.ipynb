{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üß† LLM Interpretability - Simple Pipeline\n",
    "\n",
    "Train neural networks to interpret and modify other neural networks' weights.\n",
    "\n",
    "**Process:**\n",
    "1. Generate dataset of clean vs corrupted models\n",
    "2. Upload to HuggingFace Hub\n",
    "3. Train StarCoder2-3B with LoRA to interpret weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "#@title üöÄ Setup & Install Dependencies\n",
    "\n",
    "# Clone repository and install\n",
    "!git clone https://github.com/maximus-powers/llm-interpretability.git\n",
    "%cd llm-interpretability\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q accelerate datasets transformers[torch] peft tensorboard huggingface_hub\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üìä VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Using CPU (will be slower)\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "config"
   },
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è Dataset Generation Configuration\n",
    "\n",
    "NUM_EXAMPLES = 500 #@param {type:\"integer\"}\n",
    "MIN_DEGRADATION = 0.05 #@param {type:\"number\"}\n",
    "HUB_USERNAME = \"maximus-powers\" #@param {type:\"string\"}\n",
    "DATASET_NAME = \"llm-interpretability-v1\" #@param {type:\"string\"}\n",
    "PRIVATE_DATASET = False #@param {type:\"boolean\"}\n",
    "\n",
    "HUB_DATASET_NAME = f\"{HUB_USERNAME}/{DATASET_NAME}\"\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"   Examples: {NUM_EXAMPLES}\")\n",
    "print(f\"   Min degradation: {MIN_DEGRADATION}\")\n",
    "print(f\"   Hub dataset: {HUB_DATASET_NAME}\")\n",
    "print(f\"   Private: {PRIVATE_DATASET}\")\n",
    "print(f\"   Estimated time: ~{NUM_EXAMPLES // 50 * 2:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "login"
   },
   "outputs": [],
   "source": [
    "#@title üîê HuggingFace Login\n",
    "\n",
    "HF_TOKEN = \"\" #@param {type:\"string\"}\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"‚úÖ Logged in to HuggingFace Hub\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please enter your HuggingFace token above\")\n",
    "    print(\"   Get token from: https://huggingface.co/settings/tokens\")\n",
    "    print(\"   Make sure it has 'Write' permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "generate"
   },
   "outputs": [],
   "source": [
    "#@title üè≠ Generate Dataset\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(f\"üè≠ Starting dataset generation...\")\n",
    "print(f\"‚è±Ô∏è  Estimated time: {NUM_EXAMPLES // 50 * 2:.1f} minutes\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Build command\n",
    "cmd = [\n",
    "    \"python\", \"training_data/dataset_generation_pipeline.py\",\n",
    "    \"--num_examples\", str(NUM_EXAMPLES),\n",
    "    \"--dataset_name\", \"local_dataset\",\n",
    "    \"--min_degradation\", str(MIN_DEGRADATION),\n",
    "    \"--upload_to_hub\",\n",
    "    \"--hub_dataset_name\", HUB_DATASET_NAME,\n",
    "    \"--hub_token\", HF_TOKEN,\n",
    "    \"--verbose\"\n",
    "]\n",
    "\n",
    "if PRIVATE_DATASET:\n",
    "    cmd.append(\"--private\")\n",
    "\n",
    "# Run generation with live output\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Use Popen for real-time output\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                          text=True, bufsize=1, universal_newlines=True)\n",
    "\n",
    "# Print output in real-time\n",
    "for line in process.stdout:\n",
    "    print(line.rstrip())\n",
    "\n",
    "# Wait for completion\n",
    "return_code = process.wait()\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "print(\"-\" * 60)\n",
    "print(f\"‚è±Ô∏è  Completed in {generation_time/60:.1f} minutes\")\n",
    "\n",
    "if return_code == 0:\n",
    "    print(\"‚úÖ Dataset generation successful!\")\n",
    "    print(f\"ü§ó Dataset URL: https://huggingface.co/datasets/{HUB_DATASET_NAME}\")\n",
    "else:\n",
    "    print(f\"‚ùå Generation failed (return code: {return_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "preview"
   },
   "outputs": [],
   "source": [
    "#@title üëÄ Preview Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Load dataset from Hub\n",
    "    dataset = load_dataset(HUB_DATASET_NAME)\n",
    "    \n",
    "    print(f\"üìä Dataset Info:\")\n",
    "    print(f\"   Train examples: {len(dataset['train'])}\")\n",
    "    print(f\"   Validation examples: {len(dataset['validation'])}\")\n",
    "    print(f\"   Columns: {dataset['train'].column_names}\")\n",
    "    \n",
    "    # Show example\n",
    "    example = dataset['train'][0]\n",
    "    metadata = json.loads(example['metadata'])\n",
    "    \n",
    "    print(f\"\\nüìù Example Row:\")\n",
    "    print(f\"   Corrupted pattern: {metadata.get('corrupted_pattern', 'unknown')}\")\n",
    "    print(f\"   Clean accuracy: {metadata.get('clean_accuracy', 0):.4f}\")\n",
    "    print(f\"   Noisy accuracy: {metadata.get('noisy_accuracy', 0):.4f}\")\n",
    "    print(f\"   Degradation: {metadata.get('accuracy_diff', 0):.4f}\")\n",
    "    print(f\"   Prompt length: {len(example['prompt'])} chars\")\n",
    "    print(f\"   Completion length: {len(example['completion'])} chars\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Sample Prompt (first 500 chars):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(example['prompt'][:500] + \"...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"\\nüìÑ Sample Completion (first 300 chars):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(example['completion'][:300] + \"...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not load dataset: {e}\")\n",
    "    print(\"   Make sure dataset generation completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
